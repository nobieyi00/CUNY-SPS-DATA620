Week 4: Assignment
NNAEMEZUE OBI-EYISI
Centrality measures can be used to predict (positive or negative) outcomes for a node.
Your task in this week’s assignment is to identify an interesting set of network data that is available on the web (either through web scraping or web APIs) that could be used for analyzing and comparing centrality measures across nodes.  As an additional constraint, there should be at least one categorical variable available for each node (such as “Male” or “Female”; “Republican”, “Democrat,” or “Undecided”, etc.)
In addition to identifying your data source, you should create a high level plan that describes how you would load the data for analysis, and describe a hypothetical outcome that could be predicted from comparing degree centrality across categorical groups.
For this week’s assignment, you are not required to actually load or analyze the data.  Please see also Project 1 below.
You may work in a small group on the assignment. 

To do this, I will download a dataset using the http://vlado.fmf.uni-lj.si/pub/networks/data/esna/centrality.htm dataset; python modules: Pandas, NetworkX, and CSV;.

I will extract data of “129 vertices (publications), 613 arcs (citations, pointing towards the citing paper), no edges, no loops, line values (1 - regular citation, 2 - double citation, which is possible if the citing paper or the cited paper refers to two mutual citing papers shrunk to one combined vertex)”.
I will build a network structure wherein individual publication are the primary nodes, and citations are associated with them (edges). In this we will be able to examine the publications which have the most citations and are central to the network. In addition we compare the double citation papers versus regular citation paper
